---
layout: page
title: "arXiv:1611.07004: Image-to-Image Translation with Conditional Adversarial Networks"
description: ""
category:
tags: ["papers", "machine_learning", "deep_learning", "gan"]
---

![](/assets/images/papers/1611_07004_02.png)


### Generator

* Assume the training images are **source** and **target**.
* We want to generate a **result** image from **source** and **result** must be simular to **target**.
* result = G(source).
* Use an auto-encoder as the generator.
* Use skip connections between mirrored layers to preserve structures.


### Discriminator

* Concatenate **source** and **target** as positive examples.
* Concatenate **source** and **result** as negative examples.
* Use PatchGAN as GAN loss.
* Add L1 loss (**target** and **result**) to reduce blurring

### PatchGAN

* In the final layer of discriminator, use sigmoid as activation function.
* Reduce mean all neurons after sigmoid, optimize it.
* Patch = receptive field. The area on the first layer that affect a single pixel on the final layer.

### Implementation

[GitHub](https://github.com/imironhead/ml_gans/tree/master/pix2pix)
